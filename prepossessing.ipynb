{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一、读取《复仇者联盟4》的好评，中评，差评评论数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  import sys\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "#好评\n",
    "pos_com =  pd.read_csv('comments_sets/复仇者联盟4_好评.txt',sep = 'ssr',encoding = 'utf-8',header = None)\n",
    "# sep设置为文档内不包含的内容，否则出错\n",
    "pos_com.columns = ['comments']\n",
    "\n",
    "#中评\n",
    "mid_com  = pd.read_csv('comments_sets/复仇者联盟4_中评.txt',sep = 'ssr',encoding = 'utf-8',header = None)\n",
    "mid_com.columns = ['comments']\n",
    "\n",
    "\n",
    "#差评\n",
    "neg_com = pd.read_csv('comments_sets/复仇者联盟4_差评.txt',sep = 'ssr',encoding = 'utf-8',header = None)\n",
    "neg_com.columns = ['comments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>如果你不喜欢这部电影，说明他不是为你准备的，故事的终章是为读过故事的人准备的</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>我是一个90后，我曾经很羡慕“上一代人”：40年前的观众，他们的影院里有星战正传三部曲的落幕...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>托尼说好要回归家庭、陪伴家人，可最终还是选择了重出江湖，因为责任和使命，因为“我是钢铁侠”。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>美队曾经错过了和卡特的约会，错过陪伴卡特的70年，后来又出席卡特的葬礼，亲自送挚爱上路，感谢...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>黑寡妇高尚、豪迈、英勇、无畏，和钢铁侠并列最伟大的复仇者。</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            comments\n",
       "0             如果你不喜欢这部电影，说明他不是为你准备的，故事的终章是为读过故事的人准备的\n",
       "1  我是一个90后，我曾经很羡慕“上一代人”：40年前的观众，他们的影院里有星战正传三部曲的落幕...\n",
       "2     托尼说好要回归家庭、陪伴家人，可最终还是选择了重出江湖，因为责任和使命，因为“我是钢铁侠”。\n",
       "3  美队曾经错过了和卡特的约会，错过陪伴卡特的70年，后来又出席卡特的葬礼，亲自送挚爱上路，感谢...\n",
       "4                      黑寡妇高尚、豪迈、英勇、无畏，和钢铁侠并列最伟大的复仇者。"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_com.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "好评的评论数为： (68163,)\n",
      "中评的评论数为： (23484,)\n",
      "差评的评论数为： (23490,)\n"
     ]
    }
   ],
   "source": [
    "comment_pos = pos_com['comments']\n",
    "comment_mid = mid_com['comments']\n",
    "comment_neg = neg_com['comments']\n",
    "print('好评的评论数为：',comment_pos.shape)\n",
    "print('中评的评论数为：',comment_mid.shape)\n",
    "print('差评的评论数为：',comment_neg.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二、去除重复词及水军评论"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def condense_1(str):\n",
    "\t# 这里i代表每次处理的字符单位数，如i=1时处理“好好好好”的情况，i=2时处理“很好很好很好”的情况\n",
    "\t# i=1&i=2时用一种处理方式，即当重复数量>2时才进行压缩，因为出现“滔滔不绝”、“美的的确好”\n",
    "\t# 跟“容我思考思考”“这真的真的好看”等不好归为冗余的情况。但当出现3次及以上时基本就是冗余了。\n",
    "\tfor i in [1, 2]:\n",
    "\t\tj = 0\n",
    "\t\twhile j < len(str)-2*i:\n",
    "\t\t\t#判断重复了至少两次\n",
    "\t\t\tif str[j: j+i] == str[j+i: j+2*i] and str[j: j+i] == str[j+2*i: j+3*i]:\n",
    "\t\t\t\tk = j+2*i\n",
    "\t\t\t\twhile k+i<len(str) and str[j: j+i]==str[k+i: k+2*i]:\n",
    "\t\t\t\t\tk += i\n",
    "\t\t\t\tstr = str[: j+i] + str[k+i:]\n",
    "\t\t\tj += 1\n",
    "\t\ti += 1\n",
    "\t\n",
    "\t# i=3&i=4时用一种处理方式，当重复>1时就进行压缩，因为3个字以上时重复不再构成成语或其他常用语，\n",
    "\t# 基本上即使冗余了。因为大于五个字的重复比较少出现，为了减少算法复杂度可以只处理到i=4。\n",
    "\tfor i in [3, 4, 5]:\n",
    "\t\tj = 0\n",
    "\t\twhile j < len(str)-2*i:\n",
    "\t\t\t#判断重复了至少一次\n",
    "\t\t\tif str[j: j+i]==str[j+i: j+2*i]:\n",
    "\t\t\t\tk = j+i\n",
    "\t\t\t\twhile k+i<len(str) and str[j: j+i]==str[k+i: k+2*i]:\n",
    "\t\t\t\t\tk += i\n",
    "\t\t\t\tstr = str[: j+i] + str[k+i:]\n",
    "\t\t\tj += 1\n",
    "\t\ti += 1\n",
    "\t\n",
    "\treturn str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "好评的总字符长度为： 5043387\n",
      "中评的总字符长度为： 1814759\n",
      "差评的总字符长度为： 1629345\n"
     ]
    }
   ],
   "source": [
    "#总评论的字符长度\n",
    "print('好评的总字符长度为：',comment_pos.astype('str').apply(lambda x: len(x)).sum())\n",
    "print('中评的总字符长度为：',comment_mid.astype('str').apply(lambda x: len(x)).sum())\n",
    "print('差评的总字符长度为：',comment_neg.astype('str').apply(lambda x: len(x)).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "去除重复词后的好评的总字符长度为： 5014525\n",
      "去除重复词后的中评的总字符长度为： 1802192\n",
      "去除重复词后的差评的总字符长度为： 1621282\n"
     ]
    }
   ],
   "source": [
    "data1_pos = comment_pos.astype('str').apply(lambda x: condense_1(x))  # 去除重复词\n",
    "data1_mid = comment_mid.astype('str').apply(lambda x: condense_1(x))  # 去除重复词\n",
    "data1_neg = comment_neg.astype('str').apply(lambda x: condense_1(x))  # 去除重复词\n",
    "\n",
    "#去除重复词后的字符长度\n",
    "print('去除重复词后的好评的总字符长度为：',data1_pos.apply(lambda x: len(x)).sum())\n",
    "print('去除重复词后的中评的总字符长度为：',data1_mid.apply(lambda x: len(x)).sum())\n",
    "print('去除重复词后的差评的总字符长度为：',data1_neg.apply(lambda x: len(x)).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>评论</th>\n",
       "      <th>长度</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>一群好几百岁的人叽叽歪歪像一群青春期的小孩，三个小时的时长就靠没完没了的与过去的自己相遇+废...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>将近300元买的杜比首映场，是真的不值。除了花里胡哨的特效外，一无是处，没有插科打诨和反高潮...</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>前20分钟真的以为罗素兄弟要捧出什么好菜，适量精准的文戏和反高潮的设置让我眼前一亮。然后电影...</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>不得不承认流量在这个时代主宰世界</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>三小时超长CP混剪，还是水准贼烂的那种，十年你就给我这个丢人的玩意作答卷？</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  评论   长度\n",
       "0  一群好几百岁的人叽叽歪歪像一群青春期的小孩，三个小时的时长就靠没完没了的与过去的自己相遇+废...   61\n",
       "1  将近300元买的杜比首映场，是真的不值。除了花里胡哨的特效外，一无是处，没有插科打诨和反高潮...  124\n",
       "2  前20分钟真的以为罗素兄弟要捧出什么好菜，适量精准的文戏和反高潮的设置让我眼前一亮。然后电影...  350\n",
       "3                                   不得不承认流量在这个时代主宰世界   16\n",
       "4              三小时超长CP混剪，还是水准贼烂的那种，十年你就给我这个丢人的玩意作答卷？   37"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2_pos = data1_pos.apply(lambda x: len(x))\n",
    "data2_mid = data1_mid.apply(lambda x: len(x))\n",
    "data2_neg = data1_neg.apply(lambda x: len(x))\n",
    "\n",
    "data3_pos = pd.concat((data1_pos, data2_pos), axis = 1)  # 合并\n",
    "data3_pos.columns = ['评论','长度']\n",
    "data3_mid = pd.concat((data1_mid, data2_mid), axis = 1)  # 合并\n",
    "data3_mid.columns = ['评论','长度']\n",
    "data3_neg = pd.concat((data1_neg, data2_neg), axis = 1)  # 合并\n",
    "data3_neg.columns = ['评论','长度']\n",
    "\n",
    "data3_neg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3      479\n",
       "4      690\n",
       "5      893\n",
       "6      297\n",
       "7      596\n",
       "8     1494\n",
       "9     1076\n",
       "10    1580\n",
       "11    2849\n",
       "12    1376\n",
       "Name: 长度, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3_pos['长度'].value_counts().sort_index()[:10]  # 好评长度前十的数量统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "好评非水军评论 (66101,)\n",
      "中评非水军评论 (23109,)\n",
      "差评非水军评论 (22279,)\n"
     ]
    }
   ],
   "source": [
    "data4_pos = data3_pos.loc[data3_pos['长度'] > 5, '评论']  # 筛选长度大于5的评论\n",
    "print('好评非水军评论',data4_pos.shape)\n",
    "\n",
    "data4_mid = data3_mid.loc[data3_mid['长度'] > 5, '评论']  # 筛选长度大于5的评论\n",
    "print('中评非水军评论',data4_mid.shape)\n",
    "\n",
    "data4_neg = data3_neg.loc[data3_neg['长度'] > 5, '评论']  # 筛选长度大于5的评论\n",
    "print('差评非水军评论',data4_neg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               如果你不喜欢这部电影，说明他不是为你准备的，故事的终章是为读过故事的人准备的\n",
       "1    我是一个90后，我曾经很羡慕“上一代人”：40年前的观众，他们的影院里有星战正传三部曲的落幕...\n",
       "2       托尼说好要回归家庭、陪伴家人，可最终还是选择了重出江湖，因为责任和使命，因为“我是钢铁侠”。\n",
       "3    美队曾经错过了和卡特的约会，错过陪伴卡特的70年，后来又出席卡特的葬礼，亲自送挚爱上路，感谢...\n",
       "4                        黑寡妇高尚、豪迈、英勇、无畏，和钢铁侠并列最伟大的复仇者。\n",
       "Name: 评论, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data4_pos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 三、分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\p'ro\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.771 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['我', '爱', '北京', '天安门', '，', '天安门', '前', '国旗', '升']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jieba\n",
    "#example\n",
    "list(jieba.cut('我爱北京天安门，天安门前国旗升'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [如果, 你, 不, 喜欢, 这部, 电影, ，, 说明, 他, 不是, 为, 你, 准备,...\n",
       "1    [我, 是, 一个, 90, 后, ，, 我, 曾经, 很, 羡慕, “, 上, 一代人, ...\n",
       "2    [托尼, 说好, 要, 回归, 家庭, 、, 陪伴, 家人, ，, 可, 最终, 还是, 选...\n",
       "3    [美队, 曾经, 错过, 了, 和, 卡特, 的, 约会, ，, 错过, 陪伴, 卡特, 的...\n",
       "4    [黑寡妇, 高尚, 、, 豪迈, 、, 英勇, 、, 无畏, ，, 和, 钢铁, 侠, 并列...\n",
       "Name: 评论, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#好评\n",
    "data5_pos = data4_pos.apply(lambda x: list(jieba.cut(x)))  \n",
    "#中评\n",
    "data5_mid = data4_mid.apply(lambda x: list(jieba.cut(x))) \n",
    "#差评\n",
    "data5_neg = data4_neg.apply(lambda x: list(jieba.cut(x)))\n",
    "\n",
    "data5_pos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 四、去停用词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#读取网上下载的停用词表\n",
    "stop = pd.read_csv('stoplist.txt', sep='aab', encoding = 'utf-8', header = None)\n",
    "# sep设置为文档内不包含的内容，否则出错\n",
    "stop = ['漫威','电影'] + [' ', ''] + list(stop[0]) \t#Pandas自动过滤了空格符，这里手动添加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data6_pos = data5_pos.apply(lambda x: [i for i in x if i not in stop])\n",
    "\n",
    "data6_mid = data5_mid.apply(lambda x: [i for i in x if i not in stop])\n",
    "\n",
    "data6_neg = data5_neg.apply(lambda x: [i for i in x if i not in stop])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "去停用词后的好评字符总长: 1353167 减少长度: 1753310\n",
      "去停用词后的中评字符总长: 487446 减少长度: 626274\n",
      "去停用词后的差评字符总长: 450838 减少长度: 548276\n"
     ]
    }
   ],
   "source": [
    "print('去停用词后的好评字符总长:',data6_pos.apply(lambda x: len(x)).sum(),'减少长度:',\\\n",
    "     data5_pos.apply(lambda x: len(x)).sum() - data6_pos.apply(lambda x: len(x)).sum())\n",
    "\n",
    "print('去停用词后的中评字符总长:',data6_mid.apply(lambda x: len(x)).sum(),'减少长度:',\\\n",
    "     data5_mid.apply(lambda x: len(x)).sum() - data6_mid.apply(lambda x: len(x)).sum())\n",
    "\n",
    "print('去停用词后的差评字符总长:',data6_neg.apply(lambda x: len(x)).sum(),'减少长度:',\\\n",
    "     data5_neg.apply(lambda x: len(x)).sum() - data6_neg.apply(lambda x: len(x)).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                             [喜欢, 这部, 故事, 终章, 读过, 故事]\n",
       "1    [90, 羡慕, 一代人, 40, 年前, 观众, 影院, 里, 星战, 正传, 三部曲, ...\n",
       "2    [托尼, 说好, 回归, 家庭, 陪伴, 家人, 最终, 选择, 重出江湖, 责任, 使命,...\n",
       "3    [美队, 错过, 卡特, 约会, 错过, 陪伴, 卡特, 70, 年, 出席, 卡特, 葬礼...\n",
       "4                [黑寡妇, 高尚, 豪迈, 英勇, 无畏, 钢铁, 侠, 并列, 复仇者]\n",
       "Name: 评论, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data6_pos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [感情, 分, 合格, 水准, 通篇, 流水账, 观感, 第三部, 这类, 片, 无所谓, ...\n",
       "1    [钢铁, 侠, 头号, 一哥, 支撑, 复联, 女拳, 队长, 角色, 定位, 彻头彻尾, ...\n",
       "2    [三个, 小时, 剧情, 太, 拖沓, 成, 七龙珠, 寻宝, 堆砌, 拼凑, 剧情, 浪费...\n",
       "3    [复联, 一场, 寓言故事, 黑色, 歌剧, 惊艳, 不为过, 所有人, 猜想, 复联, 何...\n",
       "4    [抱歉, 谢幕, 实在, 吹, 出口, 剧情, 逻辑, bug, care, 人物, ooc...\n",
       "Name: 评论, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data6_mid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [一群, 好几百, 岁, 叽叽, 歪歪, 一群, 青春期, 小孩, 三个, 小时, 时长, ...\n",
       "1    [300, 杜比, 首映, 场, 真的, 不值, 花里胡哨, 特效, 外, 一无是处, 插科...\n",
       "2    [前, 20, 分钟, 真的, 罗素, 兄弟, 捧, 好菜, 适量, 精准, 文戏, 反, ...\n",
       "3                                   [承认, 流量, 时代, 主宰世界]\n",
       "4    [小时, 超长, CP, 混剪, 水准, 贼, 烂, 那种, 十年, 丢人, 玩意, 作, 答卷]\n",
       "Name: 评论, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data6_neg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存好评，中评，差评的经过预处理的数据\n",
    "data6_pos.to_csv('comments_sets/pre_pos.txt',encoding = 'utf-8', index = False, header = False)\n",
    "\n",
    "data6_mid.to_csv('comments_sets/pre_mid.txt',encoding = 'utf-8', index = False, header = False)\n",
    "\n",
    "data6_neg.to_csv('comments_sets/pre_neg.txt',encoding = 'utf-8', index = False, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
